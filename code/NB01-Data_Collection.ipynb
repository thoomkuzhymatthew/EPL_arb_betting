{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Collection:\n",
    "\n",
    "**Author:** Matthew Thoomkuzhy\n",
    "\n",
    "**Date last edited:** 4/2/2025\n",
    "\n",
    "**Objective:** Collecting historical match data regarding all English Premier League matches over the past 4 years from the Odds API.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime , timedelta\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Getting API  Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Odds-API In-built function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoricalOddsAPIClient:\n",
    "    def __init__(self, api_key, base_url=\"https://api.the-odds-api.com/v4/historical\"):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "\n",
    "    def construct_historical_url(self, sport, date, regions=\"us\", markets=\"h2h\", odds_format=\"american\"):\n",
    "        return f\"{self.base_url}/sports/{sport}/odds/?apiKey={self.api_key}&regions={regions}&markets={markets}&oddsFormat={odds_format}&date={date}\"\n",
    "\n",
    "    def fetch_historical_odds(self, sport, date, regions=\"us\", markets=\"h2h\", odds_format=\"american\"):\n",
    "        url = self.construct_historical_url(sport, date, regions, markets, odds_format)\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The key problem is that it the inbuilt function only returns data for one time period, but not all data within a range\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Functions needed for NB01\n",
    "\n",
    "I have written 2  more functions:\n",
    "\n",
    "1. save_to_json: saves data to the raw folder ans dumps data from a request in a file\n",
    "\n",
    "2. fetch_daily_odds: takes a start date, end date and timestamp. It collects data each day at that given timestamp then concatenates the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(data, file_name, folder=\"../data/raw/\"):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    file_path = os.path.join(folder, f\"{file_name}.json\")\n",
    "    try:\n",
    "        with open(file_path, \"w\") as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "        print(f\"Data saved to {file_path}.\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error saving data: {e}\")\n",
    "\n",
    "def fetch_odds(client, sport, start_date, end_date, regions, markets, odds_format, daily_time=\"12:00:00Z\"):\n",
    "    current_date = datetime.fromisoformat(start_date)\n",
    "    end_date = datetime.fromisoformat(end_date)\n",
    "    all_data = []\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        date_with_time = current_date.strftime(f\"%Y-%m-%dT{daily_time}\")\n",
    "        print(f\"Fetching historical odds for {sport} on {date_with_time}...\")\n",
    "        response = client.fetch_historical_odds(sport, date_with_time, regions, markets, odds_format)\n",
    "\n",
    "        if response and \"data\" in response:\n",
    "            all_data.extend(response[\"data\"])  # Extract only the match data\n",
    "        else:\n",
    "            print(f\"No data fetched for {date_with_time}.\")\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1.4 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Parameters, change according to what you want to find\n",
    "    sport = \"soccer_epl\"\n",
    "    start_date = \"2020-06-10\"\n",
    "    end_date = \"2024-12-30\"\n",
    "    regions = \"uk\"\n",
    "    markets = \"h2h\"\n",
    "    odds_format = \"decimal\"\n",
    "\n",
    "    client = HistoricalOddsAPIClient(API_KEY)\n",
    "\n",
    "    # Fetch data for the date range\n",
    "    all_data = fetch_odds(client, sport, start_date, end_date, regions, markets, odds_format)\n",
    "\n",
    "    if all_data:\n",
    "        file_name = f\"{sport}_odds_{start_date}_to_{end_date}\"\n",
    "        save_to_json(all_data, file_name)\n",
    "    else:\n",
    "        print(\"No data fetched for the specified date range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1.5 Code For Splitting Large File\n",
    "\n",
    "- The data collected was far too large to be pushed to github (300MB)\n",
    "\n",
    "- So I  have written code to split the large JSON file into several smaller JSON files categorised by month and year e.g. 2020_06\n",
    "\n",
    "- It saves the categorised events in a folder within raw called 'grouped events'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_json_by_month(file_path):\n",
    "    \"\"\"\n",
    "    Splits a large JSON file into smaller files, grouping by the commence time's month.\n",
    "\n",
    "    :param file_path: Path to the large JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the large JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Dictionary to hold grouped events\n",
    "        grouped_data = {}\n",
    "\n",
    "        # Process each event\n",
    "        for event in data:\n",
    "            commence_time = event.get(\"commence_time\")\n",
    "            if commence_time:\n",
    "                # Extract year and month (e.g., \"2020-06\")\n",
    "                month_key = datetime.fromisoformat(commence_time.replace(\"Z\", \"\")).strftime(\"%Y-%m\")\n",
    "\n",
    "                # Group events by month\n",
    "                if month_key not in grouped_data:\n",
    "                    grouped_data[month_key] = []\n",
    "                grouped_data[month_key].append(event)\n",
    "\n",
    "        # Save grouped events into separate files\n",
    "        output_dir = \"../data/raw/grouped_events\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        for month, events in grouped_data.items():\n",
    "            output_file = os.path.join(output_dir, f\"events_{month}.json\")\n",
    "            with open(output_file, 'w') as out_file:\n",
    "                json.dump(events, out_file, indent=4)\n",
    "\n",
    "        print(f\"Files saved in directory: {output_dir}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"../data/raw/soccer_epl_odds_2020-06-10_to_2024-12-30.json\"  \n",
    "split_json_by_month(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
